{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomazzaferro/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1035: UserWarning: Duplicate key in file \"/Users/carlomazzaferro/.matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from variantannotation import annotate_batch\n",
    "from variantannotation import myvariant_parsing_utils\n",
    "from variantannotation import mongo_DB_export\n",
    "from variantannotation import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \".../CSV to be tested\"\n",
    "csv_file = \"test_file.csv\"\n",
    "vcf_file = \"test_file_.vcf\"\n",
    "os.chdir(filepath)\n",
    "\n",
    "ANNOVAR_PATH = '/database/annovar/'\n",
    "IN_PATH = '.../file.vcf'\n",
    "OUT_PATH = '.../annovar_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run only if ANNOVAR is properly installed and databases in memory\n",
    "utilities.run_annovar(ANNOVAR_PATH, IN_PATH, OUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 1: export data to MongoDB by chunks, iteratively. \n",
    "\n",
    "This method is well-fitted for large files. Only the 1000 documents are held in memory and processed at a time, instead of attempting to parse and process an entire csv file at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As soon as you run the scripts from variantannotaiton the data will automatically be stored to it. Database and collection name should be specified, and there must be a running MongoDB connection. The script will set up a client to communicate between python (through pymongo) and the the database.\n",
    "\n",
    "In general, the shell command:\n",
    "\n",
    "``mongod --dbpath ../data/db``\n",
    "\n",
    "(data/db is the designated location where the data will be stored) will initiate MongoDB. After this, the script should store data to the directory automatically.\n",
    "\n",
    "For pymongo, and more information on how to set up a Mongo Database: https://docs.mongodb.com/getting-started/python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 1 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 2 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 3 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 4 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 5 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 6 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 7 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 8 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 9 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 10 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 11 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 12 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 13 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 14 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 15 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 16 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 17 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 18 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 19 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 20 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 21 of 22\n",
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-252...done.\n",
      "Joining lists ...\n",
      "Parsing to MongoDB ...\n",
      "Step: 22 of 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunksize = 1000\n",
    "step = 0\n",
    "\n",
    "#Get variant list. Should always be the first step after running ANNOVAR\n",
    "open_file = myvariant_parsing_utils.VariantParsing()\n",
    "list_file = open_file.get_variants_from_vcf(vcf_file)\n",
    "\n",
    "#Name Collection & DB\n",
    "collection_name = 'ANNOVAR_MyVariant_chunks'\n",
    "db_name = 'My_Variant_Database'\n",
    "\n",
    "#Run process, and export (export happens every time 1000 variants are processed and joined)\n",
    "as_batch = annotate_batch.AnnotationMethods()\n",
    "as_batch.by_chunks(list_file, chunksize, step, csv_file, collection_name, db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 2: usign full file, and holding it in memory \n",
    "Works well for small files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing knownGene info ...\n",
      "Processing nci60 info ...\n",
      "Processing tfbsConsSites info ...\n",
      "Processing genomicSuperDups info ...\n",
      "Processing cytoBand info ...\n",
      "Creating hgvs key ...\n",
      "Processing genotype call info ...\n",
      "Transforming to JSON from dataFrame\n",
      "cleaning up...\n",
      "Done\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-17000...done.\n",
      "querying 17001-18000...done.\n",
      "querying 18001-19000...done.\n",
      "querying 19001-20000...done.\n",
      "querying 20001-21000...done.\n",
      "querying 21001-21252...done.\n",
      "Joining lists ...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#get variant list. Should always be the first step after running ANNOVAR\n",
    "open_file = myvariant_parsing_utils.VariantParsing()\n",
    "list_file = open_file.get_variants_from_vcf(vcf_file)\n",
    "\n",
    "#Run process, data saved to joint_list\n",
    "as_one_file = annotate_batch.AnnotationMethods()\n",
    "joint_list = as_one_file.full_file(list_file, csv_file)\n",
    "\n",
    "#Name Collection & DB\n",
    "collection_name = 'ANNOVAR_MyVariant_full'\n",
    "db_name = 'My_Variant_Database'\n",
    "\n",
    "#Export, all at once\n",
    "exporting_function = mongo_DB_export.export\n",
    "exporting_function(joint_list, collection_name, db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 3: ignore annovar, get data solely from myvariant \n",
    "Easier to run, doesn't require annovar\n",
    "Will however be incomplete (some variants will have no information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-17000...done.\n",
      "querying 17001-18000...done.\n",
      "querying 18001-19000...done.\n",
      "querying 19001-20000...done.\n",
      "querying 20001-21000...done.\n",
      "querying 21001-21252...done.\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#Get variant list form vcf file\n",
    "open_file = myvariant_parsing_utils.VariantParsing()\n",
    "list_file = open_file.get_variants_from_vcf(vcf_file)\n",
    "\n",
    "#Run process\n",
    "my_variants = annotate_batch.AnnotationMethods()\n",
    "myvariant_data = my_variants.my_variant_at_once(list_file)\n",
    "\n",
    "#Name Collection & DB\n",
    "collection_name = 'My_Variant_Info_Collection_Full'\n",
    "db_name = 'My_Variant_Database'\n",
    "\n",
    "#Export\n",
    "exporting_function = mongo_DB_export.export\n",
    "exporting_function(myvariant_data, collection_name, db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 4: ignore annovar, get data solely from myvariant \n",
    "Easier to run, doesn't require annovar. Will however be incomplete (some variants will have no information).\n",
    "Do so BY CHUNKS. Export function is built in the methods myvariant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-1000...done.\n",
      "Step: 1 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 2 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 3 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 4 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 5 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 6 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 7 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 8 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 9 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 10 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 11 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 12 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 13 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 14 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 15 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 16 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 17 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 18 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 19 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 20 of 22\n",
      "querying 1-1000...done.\n",
      "Step: 21 of 22\n",
      "querying 1-252...done.\n",
      "Step: 22 of 22\n"
     ]
    }
   ],
   "source": [
    "chunksize = 1000\n",
    "step = 0\n",
    "\n",
    "#Get variant list from vcf file\n",
    "open_file = myvariant_parsing_utils.VariantParsing()\n",
    "list_file = open_file.get_variants_from_vcf(vcf_file)\n",
    "\n",
    "#Name Collection & DB\n",
    "collection_name = 'My_Variant_Info_Collection_Chunks'\n",
    "db_name = 'My_Variant_Database'\n",
    "\n",
    "#Run process, export to MongoDB in-built\n",
    "my_variants = annotate_batch.AnnotationMethods()\n",
    "myvariant_data = my_variants.myvariant_chunks(list_file, chunksize, step, collection_name, db_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
